{"cells":[{"cell_type":"code","source":["#Zih-Cin Jain\n#zxj161530@utdallas.edu\n#Project: World Happiness Indicator\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import PCA\nfrom pyspark.ml.linalg import Vectors\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Setting FilePath\nfilePath_h2015 = \"/WHR/2015.csv\" \nfilePath_h2016 = \"/WHR/2016.csv\"\nfilePath_h2017 = \"/WHR/2017.csv\""],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Loading CSV files \nraw_df_h2015 = spark.read.option(\"header\",\"true\").option(\"InferSchema\", \"True\").csv(filePath_h2015)\nraw_df_h2016 = spark.read.option(\"header\",\"true\").option(\"InferSchema\", \"True\").csv(filePath_h2016)\nraw_df_h2017 = spark.read.option(\"header\",\"true\").option(\"InferSchema\", \"True\").csv(filePath_h2017)\n#Setting Datatype and Rename columns\ndf_h2015 = raw_df_h2015.drop('Standard Error')\\\n.withColumnRenamed('Economy (GDP per Capita)','GDP')\\\n.withColumnRenamed('Health (Life Expectancy)','Health')\\\n.drop(\"Region\")\n\ndf_h2016 = raw_df_h2016.drop('Lower Confidence Interval')\\\n.drop('Upper Confidence Interval')\\\n.withColumnRenamed('Economy (GDP per Capita)','GDP')\\\n.withColumnRenamed('Health (Life Expectancy)','Health')\\\n.drop(\"Region\")\n\ndf_h2017 = raw_df_h2017.withColumnRenamed('Happiness.Rank','Happiness Rank')\\\n.withColumnRenamed('Happiness.Score','Happiness Score')\\\n.drop('Whisker.high').drop('Whisker.low')\\\n.withColumnRenamed('Economy..GDP.per.Capita.','GDP')\\\n.withColumnRenamed('Health..Life.Expectancy.','Health')\\\n.withColumnRenamed('Trust..Government.Corruption.','Trust (Government Corruption)')\\\n.withColumnRenamed('Dystopia.Residual','Dystopia Residual')\n\ndf = df_h2015.union(df_h2016).sort(asc(\"Country\"))\nindexer = StringIndexer(inputCol=\"Country\", outputCol=\"CountryID\")\ndf = indexer.fit(df).transform(df)\ndf.cache()\nassembler = VectorAssembler(\n    inputCols=[ \"GDP\", \"Family\",\"Health\",\"Freedom\",\"Trust (Government Corruption)\",\"Generosity\",\"Dystopia Residual\"],\n    outputCol=\"features\")\noutput = assembler.transform(df)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#find correlation matrix\ndatasetUnionAllYearsPD = df_h2015.union(df_h2016).union(df_h2017).toPandas()\ncorrmat_allYears = datasetUnionAllYearsPD.corr()\nfig, axes = plt.subplots(figsize=(10, 7))\nplt.subplots_adjust(bottom=0.35)\nmask = np.zeros_like(corrmat_allYears)\nmask[np.triu_indices_from(mask)] = True\nsns.set(font_scale=0.7)\nsns.axes_style(\"white\")\nsns.heatmap(corrmat_allYears, linewidths=1, annot=True, mask=mask, vmax= 0.9, square=True, annot_kws={\"size\":8}, cmap=\"Set2\")\naxes.set_title(\" Correlation Matrix: World Happiness Report\")\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["pca_all = PCA(k=7, inputCol=\"features\", outputCol=\"PCA_Features (GDP,Family,Health,Freedom,Trust(Government Corruption),Generosity,Dystopia Residual)\")\npcaModel = pca_all.fit(output)\nresult_all = pcaModel.transform(output).select(\"PCA_Features (GDP,Family,Health,Freedom,Trust(Government Corruption),Generosity,Dystopia Residual)\")\nresult_all.show(5,truncate=False)\npca = PCA(k=4, inputCol=\"features\", outputCol=\"PCA_Features\")\npcaModel = pca.fit(output)\nresult = pcaModel.transform(output).select(\"features\", \"PCA_Features\")\nresult.show(4,truncate=False)\nprint (\"The top 4 important factors(components) for the evaluation of happiness are : GPD, Family, Health, and Freedom (all > the value of Dystopia which contains unexplainable data)\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["trainingData = df.select(\"Happiness Score\", \"GDP\",\"Family\",\"Health\",\"Freedom\").rdd\\\n  .map(lambda r: (r[0], Vectors.dense([r[1],r[2],r[3],r[4]]))).toDF().withColumnRenamed('_1','label').withColumnRenamed('_2','features')\ntestData = df_h2017.select(\"Happiness Score\", \"GDP\",\"Family\",\"Health\",\"Freedom\").rdd\\\n  .map(lambda r: (r[0], Vectors.dense([r[1],r[2],r[3],r[4]]))).toDF().withColumnRenamed('_1','label').withColumnRenamed('_2','features')\ndf2017WithFeatures = df_h2017.select(\"Country\", \"Happiness Rank\", \"Happiness Score\", \"GDP\",\"Family\",\"Health\",\"Freedom\").rdd\\\n  .map(lambda r: (r[0], r[1] ,r[2], Vectors.dense([r[3],r[4],r[5],r[6]]))).toDF().withColumnRenamed('_1','Country').withColumnRenamed('_2','Happiness Rank').withColumnRenamed('_3','Happiness Score').withColumnRenamed('_4','features')"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nregularParam = [0.4, 0.5, 0.6]\nbestRegularParam = -1\nminrmse = float('inf') # infinity\n\ntrainingData1, validationData = trainingData.randomSplit([0.66, 0.34])\nevaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n\nfor rp in regularParam:\n    lr = LinearRegression(maxIter= 10, regParam=rp)\n    model =lr.fit(trainingData1)\n    print(\"when regular parameter: %s\" %rp)\n    print(\"Coefficients: %s\" % str(model.coefficients))\n    print(\"Intercept: %s\" % str(model.intercept))\n    trainingSummary = model.summary\n    print(\"Root Mean Squared Error (RMSE) on training data : %f\" % trainingSummary.rootMeanSquaredError)\n    validation = model.transform(validationData)\n    #evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n    rmse = evaluator.evaluate(validation)\n    print(\"Root Mean Squared Error (RMSE) on validation data = %g\" % rmse)\n    \n    #rmse = trainingSummary.rootMeanSquaredError\n    if rmse < minrmse:\n         minrmse = rmse\n         bestRegularParam = rp\n          \nprint 'The best model was trained with regular parameter %s' % bestRegularParam\n    "],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["mylr = LinearRegression(maxIter= 10, regParam=bestRegularParam)\nmymodel =mylr.fit(trainingData)\npredictions = mymodel.transform(testData)\ndfPredicted2017 = df2017WithFeatures.join(predictions, df2017WithFeatures.features == predictions.features,'inner').select(\"Country\", \"Happiness Rank\", \"Happiness Score\",\"prediction\").withColumnRenamed(\"prediction\", \"Predicted Score\")\n#evaluator = RegressionEvaluator(\n#    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["from pyspark.sql import Window\nwindow = Window.orderBy(desc(\"Predicted Score\"))\ndfPredictedRank = dfPredicted2017.withColumn(\"Predicted Rank\", dense_rank().over(window))\ndfPredictedRank.show(50,False)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["from plotly.offline import plot\npd2017 = df_h2017.toPandas()\ndata = dict(type = 'choropleth', \n           colorscale = 'Portland',\n           autocolorscale = False, \n           locations = pd2017['Country'],\n           locationmode = 'country names',\n           z = pd2017['Happiness Rank'], \n           text = pd2017['Country'],\n           colorbar = {'title':'Happiness Rank'})\nlayout = dict(title = '2017 Actual Global Happiness Rank', geo = dict( showframe = False, showcoastlines = False, projection = dict( type = 'Mercator')))\nfig = dict(data = [data], layout=layout)\np1 = plot(fig, output_type = 'div')\ndisplayHTML(p1)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["from plotly.offline import plot\npdPredictedRank = dfPredictedRank.toPandas()\ndata = dict(type = 'choropleth', \n           colorscale = 'Portland',\n           autocolorscale = False, \n           locations = pdPredictedRank['Country'],\n           locationmode = 'country names',\n           z = pdPredictedRank['Predicted Rank'], \n           text = pdPredictedRank['Country'],\n           colorbar = {'title':'Happiness Rank'})\nlayout = dict(title = '2017 Predicted Global Happiness Rank', geo = dict( showframe = False, showcoastlines = False, projection = dict( type = 'Mercator')))\nfig = dict(data = [data], layout=layout)\np2 = plot(fig, output_type = 'div')\ndisplayHTML(p2)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":12}],"metadata":{"name":"Project_WHR","notebookId":745668567000272},"nbformat":4,"nbformat_minor":0}
